{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrenamiento usando las técnicas de HuggingFace"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Chequear GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pynvml import *\n",
        "\n",
        "\n",
        "def print_gpu_utilization():\n",
        "    nvmlInit()\n",
        "    handle = nvmlDeviceGetHandleByIndex(0)\n",
        "    info = nvmlDeviceGetMemoryInfo(handle)\n",
        "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
        "\n",
        "\n",
        "def print_summary(result):\n",
        "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
        "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
        "    print_gpu_utilization()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NVMLError_LibraryNotFound",
          "evalue": "NVML Shared Library Not Found",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pynvml.py:641\u001b[0m, in \u001b[0;36m_LoadNvmlLibrary\u001b[1;34m()\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[39mif\u001b[39;00m (sys\u001b[39m.\u001b[39mplatform[:\u001b[39m3\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[39m# cdecl calling convention\u001b[39;00m\n\u001b[0;32m    640\u001b[0m     \u001b[39m# load nvml.dll from %ProgramFiles%/NVIDIA Corporation/NVSMI/nvml.dll\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m     nvmlLib \u001b[39m=\u001b[39m CDLL(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(os\u001b[39m.\u001b[39;49mgetenv(\u001b[39m\"\u001b[39;49m\u001b[39mProgramFiles\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mC:/Program Files\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m\"\u001b[39;49m\u001b[39mNVIDIA Corporation/NVSMI/nvml.dll\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    642\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    643\u001b[0m     \u001b[39m# assume linux\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\joaco\\anaconda3\\envs\\huggingface\\lib\\ctypes\\__init__.py:381\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m _dlopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, mode)\n\u001b[0;32m    382\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: Could not find module 'C:\\Program Files\\NVIDIA Corporation\\NVSMI\\nvml.dll' (or one of its dependencies). Try using the full path with constructor syntax.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mNVMLError_LibraryNotFound\u001b[0m                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m print_gpu_utilization()\n",
            "Cell \u001b[1;32mIn[1], line 5\u001b[0m, in \u001b[0;36mprint_gpu_utilization\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_gpu_utilization\u001b[39m():\n\u001b[1;32m----> 5\u001b[0m     nvmlInit()\n\u001b[0;32m      6\u001b[0m     handle \u001b[39m=\u001b[39m nvmlDeviceGetHandleByIndex(\u001b[39m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m     info \u001b[39m=\u001b[39m nvmlDeviceGetMemoryInfo(handle)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pynvml.py:608\u001b[0m, in \u001b[0;36mnvmlInit\u001b[1;34m()\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnvmlInit\u001b[39m():\n\u001b[1;32m--> 608\u001b[0m     _LoadNvmlLibrary()\n\u001b[0;32m    610\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m    611\u001b[0m     \u001b[39m# Initialize the library\u001b[39;00m\n\u001b[0;32m    612\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m    613\u001b[0m     fn \u001b[39m=\u001b[39m _nvmlGetFunctionPointer(\u001b[39m\"\u001b[39m\u001b[39mnvmlInit_v2\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pynvml.py:646\u001b[0m, in \u001b[0;36m_LoadNvmlLibrary\u001b[1;34m()\u001b[0m\n\u001b[0;32m    644\u001b[0m         nvmlLib \u001b[39m=\u001b[39m CDLL(\u001b[39m\"\u001b[39m\u001b[39mlibnvidia-ml.so.1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    645\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m ose:\n\u001b[1;32m--> 646\u001b[0m     _nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)\n\u001b[0;32m    647\u001b[0m \u001b[39mif\u001b[39;00m (nvmlLib \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    648\u001b[0m     _nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pynvml.py:310\u001b[0m, in \u001b[0;36m_nvmlCheckReturn\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_nvmlCheckReturn\u001b[39m(ret):\n\u001b[0;32m    309\u001b[0m     \u001b[39mif\u001b[39;00m (ret \u001b[39m!=\u001b[39m NVML_SUCCESS):\n\u001b[1;32m--> 310\u001b[0m         \u001b[39mraise\u001b[39;00m NVMLError(ret)\n\u001b[0;32m    311\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\n",
            "\u001b[1;31mNVMLError_LibraryNotFound\u001b[0m: NVML Shared Library Not Found"
          ]
        }
      ],
      "source": [
        "print_gpu_utilization()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cargar datasets\n",
        "\n",
        "Notar que estos son de tipo \"Dataset\", un tipo que se usa en HuggingFace comunmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset glue (C:/Users/joaco/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "100%|██████████| 3/3 [00:00<00:00, 125.54it/s]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"glue\", \"cola\")\n",
        "dataset_train = dataset[\"train\"]  # Just take the training split for now\n",
        "dataset_test = dataset[\"test\"]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sentence': \"Our friends won't buy this analysis, let alone the next one we propose.\", 'label': 1, 'idx': 0}\n"
          ]
        }
      ],
      "source": [
        "print(dataset_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sentence': 'Bill whistled past the house.', 'label': -1, 'idx': 0}\n"
          ]
        }
      ],
      "source": [
        "print(dataset_test[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at C:\\Users\\joaco\\.cache\\huggingface\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-362372c6dcd81c36.arrow\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "def tokenize_dataset(data):\n",
        "    # Keys of the returned dictionary will be added to the dataset as columns\n",
        "    return tokenizer(data[\"sentence\"], truncation=True)\n",
        "\n",
        "dataset_train = dataset_train.map(tokenize_dataset, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "    num_rows: 8551\n",
            "})\n",
            "{'sentence': \"Our friends won't buy this analysis, let alone the next one we propose.\", 'label': 1, 'idx': 0, 'input_ids': [101, 3458, 2053, 1281, 112, 189, 4417, 1142, 3622, 117, 1519, 2041, 1103, 1397, 1141, 1195, 17794, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "print(dataset_train)\n",
        "print(dataset_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at C:\\Users\\joaco\\.cache\\huggingface\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-24398a31ef968442.arrow\n"
          ]
        }
      ],
      "source": [
        "dataset_test = dataset_test.map(tokenize_dataset, batched=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparar dataset y modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 5\n",
        "batches_per_epoch = len(dataset_train) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2, id2label=id2label, label2id=label2id)\n",
        "\n",
        "tf_train_set = model.prepare_tf_dataset(\n",
        "    dataset_train,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set = model.prepare_tf_dataset(\n",
        "    dataset_test,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "model.compile(optimizer=optimizer) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "\n",
        "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entrenar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=3, callbacks=metric_callback)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predecir"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "EkFGgLo7s8tE",
        "bsVED_Pw1WJO",
        "XzdMTP1z_Xhe"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
